# Copyright (c) 2025, Williams.Wang. All rights reserved. Use restricted under LICENSE terms.

"""
è¯­éŸ³è½¬å†™æœåŠ¡æ¨¡å—

é€šè¿‡DeepInfra Whisper APIå°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡æœ¬ã€‚
"""

import requests
from pathlib import Path
from typing import Optional, Dict, Any, List
import time

from ..utils.config import Config
from ..utils.audio_splitter import AudioSplitter


class TranscriptionService:
    """è¯­éŸ³è½¬å†™æœåŠ¡ç±»"""
    
    def __init__(self, api_token: str) -> None:
        """
        åˆå§‹åŒ–è½¬å†™æœåŠ¡
        
        Args:
            api_token: DeepInfra APIå¯†é’¥
        """
        self.api_token = api_token
        self.base_url = Config.DEEPINFRA_BASE_URL
        self.model = Config.WHISPER_MODEL
        self.timeout = Config.API_TIMEOUT_SECONDS
        self.splitter = AudioSplitter()
        
    def transcribe_file(
        self, 
        audio_file: Path, 
        language: str = "zh"
    ) -> Optional[str]:
        """
        è½¬å†™éŸ³é¢‘æ–‡ä»¶
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸ºautoè‡ªåŠ¨æ£€æµ‹ï¼ˆDeepInfraä¼šè‡ªåŠ¨æ£€æµ‹ï¼‰
            
        Returns:
            Optional[str]: è½¬å†™æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        if not audio_file.exists():
            print(f"âŒ Audio file not found: {audio_file}")
            return None
            
        url = f"{self.base_url}/{self.model}"
        
        headers = {
            "Authorization": f"bearer {self.api_token}"
        }
        
        # å‡†å¤‡æ–‡ä»¶å’Œå‚æ•° - DeepInfraä½¿ç”¨ä¸åŒçš„æ ¼å¼
        try:
            with open(audio_file, "rb") as f:
                files = {
                    "audio": (audio_file.name, f, "audio/wav")
                }
                
                # å‡†å¤‡APIå‚æ•°
                data = {}
                if language and language != "auto":
                    data["language"] = language
                
                print(f"ğŸ”„ Uploading audio to DeepInfra... ({audio_file.name})")
                if language != "auto":
                    print(f"ğŸŒ Language specified: {language}")
                
                response = requests.post(
                    url,
                    headers=headers,
                    files=files,
                    data=data,
                    timeout=self.timeout
                )
                
                response.raise_for_status()
                
                # è§£æDeepInfraå“åº”æ ¼å¼
                result = response.json()
                
                # ä¿ç•™åŸå§‹å“åº”ç”¨äºè°ƒè¯•ï¼ˆä»…æ§åˆ¶å°è¾“å‡ºï¼‰
                print(f"ğŸ” API Response: {result}")
                
                # è·å–è½¬å†™æ–‡æœ¬ï¼Œä¿ç•™åŸå§‹æ ¼å¼ï¼ˆåŒ…æ‹¬ç©ºæ ¼åˆ†éš”ï¼‰
                transcript = result.get("text", "")
                
                # æ£€æŸ¥åŸå§‹æ–‡æœ¬æ˜¯å¦æœ‰æ ‡ç‚¹ç¬¦å·æˆ–ç©ºæ ¼åˆ†éš”
                if self._has_adequate_punctuation(transcript):
                    print("âœ… Original text has adequate punctuation, using as-is")
                elif self._has_word_spacing(transcript):
                    print("ğŸ“ Original text has word spacing, using as-is")
                else:
                    print("âš ï¸  Original text lacks both punctuation and spacing, attempting improvement...")
                    # å°è¯•ä½¿ç”¨æ—¶é—´æˆ³æ¨¡å‹æ”¹å–„
                    if Config.USE_TIMESTAMPED_FOR_PUNCTUATION and language in ["zh", "auto"]:
                        improved_transcript = self._transcribe_with_timestamps(audio_file, language)
                        if improved_transcript and len(improved_transcript) > len(transcript):
                            print("âœ… Improved transcript using timestamped model")
                            transcript = improved_transcript
                        else:
                            print("ğŸ“ Timestamped model didn't improve, using original")
                
                if transcript:
                    print(f"âœ… Transcription completed ({len(transcript)} characters)")
                    return transcript
                else:
                    print("âš ï¸  Empty transcription result")
                    return None
                    
        except requests.exceptions.RequestException as e:
            print(f"âŒ API request error: {e}")
            return None
        except FileNotFoundError:
            print(f"âŒ Could not read audio file: {audio_file}")
            return None
        except Exception as e:
            print(f"âŒ Transcription error: {e}")
            return None
    
    def check_api_status(self) -> bool:
        """
        æ£€æŸ¥APIè¿æ¥çŠ¶æ€
        
        Returns:
            bool: APIæ˜¯å¦å¯ç”¨
        """
        # ç®€åŒ–çš„çŠ¶æ€æ£€æŸ¥ï¼šå¦‚æœæœ‰tokenå°±è®¤ä¸ºå¯ç”¨
        # å®é™…çš„APIæµ‹è¯•ä¼šåœ¨è½¬å†™æ—¶è¿›è¡Œ
        return len(self.api_token) > 10
    
    def get_supported_languages(self) -> Dict[str, str]:
        """
        è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
        
        Returns:
            Dict[str, str]: è¯­è¨€ä»£ç å’Œåç§°çš„æ˜ å°„
        """
        # Whisperæ”¯æŒçš„ä¸»è¦è¯­è¨€
        return {
            "auto": "Auto Detect",
            "en": "English",
            "zh": "Chinese",
            "ja": "Japanese",
            "ko": "Korean",
            "es": "Spanish",
            "fr": "French",
            "de": "German",
            "ru": "Russian",
            "ar": "Arabic",
            "hi": "Hindi",
            "pt": "Portuguese",
            "it": "Italian"
        }
    
    def estimate_cost(self, audio_duration_seconds: float) -> float:
        """
        ä¼°ç®—è½¬å†™æˆæœ¬ï¼ˆåŸºäºDeepInfraçš„å®šä»·ï¼‰
        
        Args:
            audio_duration_seconds: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
            
        Returns:
            float: ä¼°ç®—æˆæœ¬ï¼ˆç¾å…ƒï¼‰
        """
        # DeepInfra Whisperå®šä»·å¤§çº¦æ˜¯$0.006/åˆ†é’Ÿ
        # è¿™ä¸ªæ•°å­—å¯èƒ½ä¼šå˜åŒ–ï¼Œä»…ä¾›å‚è€ƒ
        cost_per_minute = 0.006
        minutes = audio_duration_seconds / 60.0
        return minutes * cost_per_minute
    
    def get_transcription_info(self) -> Dict[str, Any]:
        """
        è·å–è½¬å†™æœåŠ¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: æœåŠ¡ä¿¡æ¯
        """
        return {
            "base_url": self.base_url,
            "model": self.model,
            "timeout": self.timeout,
            "has_token": bool(self.api_token),
            "token_prefix": self.api_token[:10] + "..." if self.api_token else None
        }
    
    def transcribe_large_file(self, audio_file: Path, language: str = "zh") -> Optional[str]:
        """
        è½¬å†™å¤§éŸ³é¢‘æ–‡ä»¶ï¼Œæ”¯æŒè‡ªåŠ¨åˆ†å‰²å’Œæ‹¼åˆ
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç ï¼Œé»˜è®¤ä¸ºautoè‡ªåŠ¨æ£€æµ‹
            
        Returns:
            Optional[str]: è½¬å†™æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        if not audio_file.exists():
            print(f"âŒ Audio file not found: {audio_file}")
            return None
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦éœ€è¦åˆ†å‰²
        if not self.splitter.need_split(audio_file):
            print("ğŸ“ File size is acceptable, processing directly...")
            return self.transcribe_file(audio_file, language)
        
        # æ–‡ä»¶éœ€è¦åˆ†å‰²
        file_size_mb = audio_file.stat().st_size / (1024 * 1024)
        print(f"ğŸ“ Large file detected ({file_size_mb:.1f}MB), splitting for processing...")
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºåˆ†ç‰‡
        temp_dir = Config.get_temp_dir() / f"chunks_{audio_file.stem}"
        
        try:
            # åˆ†å‰²éŸ³é¢‘æ–‡ä»¶
            chunk_files = self.splitter.split_audio_file(audio_file, temp_dir)
            
            if len(chunk_files) == 1:
                # åˆ†å‰²å¤±è´¥ï¼Œç›´æ¥å¤„ç†åŸæ–‡ä»¶
                return self.transcribe_file(audio_file, language)
            
            # æŒ‰é¡ºåºè½¬å†™æ‰€æœ‰åˆ†ç‰‡
            print(f"ğŸ”„ Transcribing {len(chunk_files)} chunks in order...")
            transcripts = []
            
            for i, chunk_file in enumerate(chunk_files):
                print(f"ğŸ“ Processing chunk {i+1}/{len(chunk_files)}: {chunk_file.name}")
                
                chunk_transcript = self.transcribe_file(chunk_file, language)
                if chunk_transcript:
                    transcripts.append({
                        "index": i,
                        "text": chunk_transcript.strip(),
                        "file": chunk_file.name
                    })
                    # æ·»åŠ å°å»¶è¿Ÿé¿å…APIé™åˆ¶
                    time.sleep(1)
                else:
                    print(f"âš ï¸  Warning: Failed to transcribe chunk {i+1}")
            
            # æ‹¼åˆè½¬å†™ç»“æœ
            if transcripts:
                combined_text = self._combine_transcripts(transcripts)
                print(f"âœ… Combined transcription completed ({len(combined_text)} characters)")
                return combined_text
            else:
                print("âŒ No successful transcriptions from chunks")
                return None
                
        except Exception as e:
            print(f"âŒ Error processing large file: {e}")
            return None
        finally:
            # æ¸…ç†ä¸´æ—¶åˆ†ç‰‡æ–‡ä»¶
            if 'chunk_files' in locals():
                self.splitter.cleanup_chunks(chunk_files)
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            try:
                if temp_dir.exists():
                    temp_dir.rmdir()
            except Exception:
                pass
    
    def _combine_transcripts(self, transcripts: List[Dict[str, Any]]) -> str:
        """
        æ™ºèƒ½æ‹¼åˆè½¬å†™æ–‡æœ¬ï¼Œå¤„ç†é‡å éƒ¨åˆ†
        
        Args:
            transcripts: è½¬å†™ç»“æœåˆ—è¡¨
            
        Returns:
            str: æ‹¼åˆåçš„å®Œæ•´æ–‡æœ¬
        """
        if not transcripts:
            return ""
        
        if len(transcripts) == 1:
            return transcripts[0]["text"]
        
        # æŒ‰ç´¢å¼•æ’åºç¡®ä¿é¡ºåºæ­£ç¡®
        transcripts.sort(key=lambda x: x["index"])
        
        combined_parts = []
        
        for i, transcript in enumerate(transcripts):
            text = transcript["text"]
            
            if i == 0:
                # ç¬¬ä¸€æ®µç›´æ¥æ·»åŠ 
                combined_parts.append(text)
            else:
                # åç»­æ®µè½éœ€è¦å¤„ç†é‡å 
                prev_text = combined_parts[-1]
                current_text = text
                
                # ç®€å•çš„é‡å å¤„ç†ï¼šæŸ¥æ‰¾å¯èƒ½çš„é‡å¤è¯æ±‡
                merged_text = self._merge_overlapping_text(prev_text, current_text)
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜æ˜¾é‡å ï¼Œç›´æ¥è¿æ¥
                if merged_text:
                    combined_parts[-1] = merged_text
                else:
                    combined_parts.append(current_text)
        
        # ä¿ç•™åŸå§‹ç©ºæ ¼åˆ†éš”ï¼Œè¿æ¥æ‰€æœ‰éƒ¨åˆ†
        if len(combined_parts) == 1:
            result = combined_parts[0]
        else:
            # ç”¨å•ä¸ªç©ºæ ¼è¿æ¥å„éƒ¨åˆ†ï¼Œä¿æŒåŸæœ‰çš„ç©ºæ ¼åˆ†éš”
            result = " ".join(combined_parts)
        
        # è½»åº¦æ¸…ç†ï¼šåªå»é™¤é¦–å°¾ç©ºæ ¼ï¼Œä¿ç•™å†…éƒ¨ç©ºæ ¼åˆ†éš”
        result = result.strip()
        
        return result
    
    def _merge_overlapping_text(self, prev_text: str, current_text: str) -> Optional[str]:
        """
        åˆå¹¶æœ‰é‡å çš„æ–‡æœ¬æ®µè½
        
        Args:
            prev_text: å‰ä¸€æ®µæ–‡æœ¬
            current_text: å½“å‰æ®µæ–‡æœ¬
            
        Returns:
            Optional[str]: åˆå¹¶åçš„æ–‡æœ¬ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°é‡å åˆ™è¿”å›None
        """
        # è·å–å‰ä¸€æ®µçš„æœ€åå‡ ä¸ªè¯å’Œå½“å‰æ®µçš„å‰å‡ ä¸ªè¯
        prev_words = prev_text.split()
        current_words = current_text.split()
        
        # æ£€æŸ¥æœ€å¤š10ä¸ªè¯çš„é‡å 
        max_overlap = min(10, len(prev_words), len(current_words))
        
        for overlap_len in range(max_overlap, 0, -1):
            prev_end = prev_words[-overlap_len:]
            current_start = current_words[:overlap_len]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼çš„è¯æ±‡åºåˆ—
            if self._words_similar(prev_end, current_start):
                # æ‰¾åˆ°é‡å ï¼Œåˆå¹¶æ–‡æœ¬
                merged_words = prev_words + current_words[overlap_len:]
                return " ".join(merged_words)
        
        return None
    
    def _words_similar(self, words1: List[str], words2: List[str]) -> bool:
        """
        æ£€æŸ¥ä¸¤ä¸ªè¯æ±‡åºåˆ—æ˜¯å¦ç›¸ä¼¼
        
        Args:
            words1: ç¬¬ä¸€ä¸ªè¯æ±‡åºåˆ—
            words2: ç¬¬äºŒä¸ªè¯æ±‡åºåˆ—
            
        Returns:
            bool: æ˜¯å¦ç›¸ä¼¼
        """
        if len(words1) != len(words2):
            return False
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similar_count = 0
        for w1, w2 in zip(words1, words2):
            if w1.lower() == w2.lower():
                similar_count += 1
        
        # å¦‚æœ80%ä»¥ä¸Šçš„è¯æ±‡ç›¸åŒï¼Œè®¤ä¸ºæ˜¯é‡å 
        similarity = similar_count / len(words1)
        return similarity >= 0.8
    
    def _needs_punctuation_improvement(self, text: str) -> bool:
        """
        åˆ¤æ–­æ–‡æœ¬æ˜¯å¦éœ€è¦æ ‡ç‚¹ç¬¦å·æ”¹å–„
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦éœ€è¦æ”¹å–„
        """
        if not text or len(text) < 10:  # é™ä½æœ€å°é•¿åº¦è¦æ±‚
            return False
        
        # è®¡ç®—æ ‡ç‚¹ç¬¦å·å¯†åº¦
        punctuation_chars = set('ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€')
        punctuation_count = sum(1 for char in text if char in punctuation_chars)
        
        # å¦‚æœæ ‡ç‚¹ç¬¦å·å°‘äºæ–‡æœ¬é•¿åº¦çš„1%ï¼Œè®¤ä¸ºéœ€è¦æ”¹å–„
        punctuation_density = punctuation_count / len(text)
        
        print(f"ğŸ“Š Punctuation analysis: {punctuation_count} punctuation marks in {len(text)} characters (density: {punctuation_density:.3f})")
        
        return punctuation_density < 0.01  # é™ä½é˜ˆå€¼
    
    def _transcribe_with_timestamps(self, audio_file: Path, language: str) -> Optional[str]:
        """
        ä½¿ç”¨å¸¦æ—¶é—´æˆ³çš„æ¨¡å‹è¿›è¡Œè½¬å†™ï¼Œæå–è¯­ä¹‰åˆ†æ®µä¿¡æ¯
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            language: è¯­è¨€ä»£ç 
            
        Returns:
            Optional[str]: æ”¹å–„åçš„è½¬å†™æ–‡æœ¬
        """
        try:
            url = f"{self.base_url}/{Config.WHISPER_TIMESTAMPED_MODEL}"
            
            headers = {
                "Authorization": f"bearer {self.api_token}"
            }
            
            with open(audio_file, "rb") as f:
                files = {
                    "audio": (audio_file.name, f, "audio/wav")
                }
                
                data = {}
                if language and language != "auto":
                    data["language"] = language
                
                response = requests.post(
                    url,
                    headers=headers,
                    files=files,
                    data=data,
                    timeout=self.timeout
                )
                
                response.raise_for_status()
                result = response.json()
                
                # ä»æ—¶é—´æˆ³ä¿¡æ¯ä¸­æå–å¹¶æ”¹å–„æ–‡æœ¬
                return self._process_timestamped_response(result)
                
        except Exception as e:
            print(f"âš ï¸  Timestamped model failed: {e}")
            return None
    
    def _process_timestamped_response(self, result: Dict[str, Any]) -> Optional[str]:
        """
        å¤„ç†å¸¦æ—¶é—´æˆ³çš„å“åº”ï¼Œä¼˜å…ˆä¿ç•™åŸå§‹æ ‡ç‚¹ï¼Œå¿…è¦æ—¶æ ¹æ®æ—¶é—´é—´éš”æ·»åŠ 
        
        Args:
            result: APIå“åº”ç»“æœ
            
        Returns:
            Optional[str]: å¤„ç†åçš„æ–‡æœ¬
        """
        try:
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ–‡æœ¬å¸¦æ ‡ç‚¹
            original_text = result.get("text", "")
            if self._has_adequate_punctuation(original_text):
                print("ğŸ“ Original text has adequate punctuation, using as-is")
                return original_text
            
            # å¦‚æœåŸå§‹æ–‡æœ¬æ²¡æœ‰è¶³å¤Ÿæ ‡ç‚¹ï¼Œä½¿ç”¨segmentsè¿›è¡Œå¤„ç†
            segments = result.get("segments", [])
            if not segments:
                return original_text
            
            print(f"ğŸ“ Processing {len(segments)} segments to add punctuation...")
            processed_text = ""
            
            for i, segment in enumerate(segments):
                text = segment.get("text", "").strip()
                if not text:
                    continue
                
                # æ·»åŠ ç©ºæ ¼åˆ†éš”ï¼ˆå¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªsegmentï¼‰
                if i > 0 and processed_text and not processed_text.endswith(" "):
                    processed_text += " "
                
                # æ£€æŸ¥å½“å‰æ®µè½æ˜¯å¦å·²æœ‰æ ‡ç‚¹
                if self._ends_with_punctuation(text):
                    processed_text += text
                else:
                    # æ ¹æ®æ—¶é—´é—´éš”å†³å®šæ ‡ç‚¹ï¼ˆè°ƒæ•´é€‚åº”å¿«è¯­é€Ÿï¼‰
                    if i < len(segments) - 1:
                        current_end = segment.get("end", 0)
                        next_start = segments[i + 1].get("start", 0)
                        gap = next_start - current_end
                        
                        # è°ƒæ•´æ—¶é—´é—´éš”é€‚åº”å¿«è¯­é€Ÿ
                        if gap > 1.5:  # é•¿åœé¡¿ï¼Œå¥å­ç»“æŸï¼ˆä»2.0é™è‡³1.5ï¼‰
                            text += "ã€‚"
                        elif gap > 0.8:  # ä¸­ç­‰åœé¡¿ï¼Œé€—å·ï¼ˆä»1.0é™è‡³0.8ï¼‰
                            text += "ï¼Œ"
                        elif gap > 0.3:  # çŸ­åœé¡¿ï¼Œé¡¿å·ï¼ˆä»0.5é™è‡³0.3ï¼‰
                            text += "ã€"
                        # æ²¡æœ‰æ˜æ˜¾åœé¡¿ï¼Œåœ¨segmenté—´æ·»åŠ ç©ºæ ¼åˆ†éš”
                    else:
                        # æœ€åä¸€ä¸ªæ®µè½ï¼Œæ·»åŠ å¥å·
                        text += "ã€‚"
                
                processed_text += text
            
            return processed_text if processed_text else original_text
            
        except Exception as e:
            print(f"âš ï¸  Error processing timestamped response: {e}")
            return result.get("text", "")
    
    def _has_adequate_punctuation(self, text: str) -> bool:
        """
        æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ ‡ç‚¹ç¬¦å·
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦æœ‰è¶³å¤Ÿæ ‡ç‚¹
        """
        if not text or len(text) < 20:
            return False
        
        # è®¡ç®—æ ‡ç‚¹ç¬¦å·å¯†åº¦
        punctuation_chars = set('ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€')
        punctuation_count = sum(1 for char in text if char in punctuation_chars)
        
        # å¦‚æœæ ‡ç‚¹ç¬¦å·å¤§äºæ–‡æœ¬é•¿åº¦çš„2%ï¼Œè®¤ä¸ºè¶³å¤Ÿï¼ˆé™ä½é˜ˆå€¼ï¼‰
        punctuation_density = punctuation_count / len(text)
        return punctuation_density >= 0.02
    
    def _has_word_spacing(self, text: str) -> bool:
        """
        æ£€æŸ¥æ–‡æœ¬æ˜¯å¦æœ‰åˆç†çš„è¯æ±‡ç©ºæ ¼åˆ†éš”
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦æœ‰è¯æ±‡åˆ†éš”
        """
        if not text or len(text) < 10:
            return False
        
        # è®¡ç®—ç©ºæ ¼å¯†åº¦
        space_count = text.count(' ')
        
        # å¦‚æœæœ‰ç©ºæ ¼ä¸”ç©ºæ ¼æ•°é‡åˆç†ï¼ˆä¸æ˜¯åªæœ‰1ä¸ªç©ºæ ¼çš„é•¿æ–‡æœ¬ï¼‰
        if space_count == 0:
            return False
        
        # å¯¹äºè¾ƒçŸ­æ–‡æœ¬ï¼Œæœ‰ç©ºæ ¼å°±ç®—åˆç†
        if len(text) < 30:
            return space_count > 0
        
        # å¯¹äºè¾ƒé•¿æ–‡æœ¬ï¼Œè¦æ±‚åˆç†çš„ç©ºæ ¼å¯†åº¦ï¼ˆè‡³å°‘æ¯20ä¸ªå­—ç¬¦æœ‰1ä¸ªç©ºæ ¼ï¼‰
        space_density = space_count / len(text)
        return space_density >= 0.05  # å¤§çº¦æ¯20ä¸ªå­—ç¬¦1ä¸ªç©ºæ ¼
    
    def _ends_with_punctuation(self, text: str) -> bool:
        """
        æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦ä»¥æ ‡ç‚¹ç»“å°¾
        """
        if not text:
            return False
        
        punctuation_chars = set('ã€‚ï¼Œï¼ï¼Ÿï¼›ï¼šã€')
        return text[-1] in punctuation_chars
    
 